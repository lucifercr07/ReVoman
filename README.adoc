= ReṼoman (Rev-Woman)
Gopal S Akshintala <gopalakshintala@gmail.com>
:Revision: 1.0
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]
:hide-uri-scheme:
:toc:
:toc-placement!:
:sourcedir: src/main/kotlin
:testdir: src/integrationTest/java
:pmtemplates: src/integrationTest/resources/pm-templates
:imagesdir: docs/images
:prewrap!:
:revoman-version: 0.31.5

____

Re - Request/Response

Ṽ - Validation

____

'''

*ReṼoman* is an API automation tool for JVM (Java/Kotlin) from the API-first SaaS company, *Salesforce*. It re-imagines API automation by letting you execute a Postman collection in a JVM program/test.

'''

[.lead]
To start with, think of it as Postman for JVM (Java/Kotlin);
that emulates this *Run* button on a collection through a Java program,
essentially translating your manual testing into Automation, without any loss.
But it's even better!

image::postman-run.png[]

[.lead]
It strikes a balance between _flexibility_
provided by low-level tools like https://rest-assured.io/[**REST Assured**] and _ease of use_
provided by UI tools like https://www.postman.com/[**Postman**]

image::hybrid-tool.png[]

== Artifact

[.lead]
Maven
[source,xml,subs=attributes+]
----
<dependency>
  <groupId>com.salesforce.revoman</groupId>
  <artifactId>revoman</artifactId>
  <version>{revoman-version}</version>
</dependency>
----
[.lead]
Bazel
[source,bzl,subs=attributes+]
----
"com.salesforce.revoman:revoman"
----
[.lead]
Gradle Kts
[source,kts,subs=attributes+]
----
implementation("com.salesforce.revoman:revoman:{revoman-version}")
----

toc::[]

.Tech-Talk given at https://www.opensourceindia.in/osi-speakers-2023/gopala-sarma-akshintala/[Open Source Conf]
image::revoman-demo-thumbnail.png[link="https://www.youtube.com/watch?v=YxeRddSFkxc&list=PLrJbJ9wDl9EC0bG6y9fyDylcfmB_lT_Or&index=2"]

== Why ReṼoman?

=== The Problem

* The majority of JVM SaaS applications are REST-based. But the API automation is done through a Mul-*T*-verse of Integration/Functional tests, E2E tests and Manual tests, each with its own frameworks, tools, and internal utilities, testing almost the same code flow.
* These custom alien automation frameworks, often built using low-level tools like https://rest-assured.io/[**REST Assured**] which are specific to a service or domain and are rigid to reuse, extend and difficult to maintain.
* This automation competes on cognitive complexity and learning curve with the Prod code, and mostly, automation wins.
* After a point, the API automation may deviate from its purpose of augmenting real end-user interaction and turns into a foot-chain for development.

image::cognitive-complexity.png[]

=== The Solution

Contrary to these custom frameworks,
almost every team uses https://www.postman.com/product/what-is-postman[*Postman*] for manual testing their APIs.
Postman collections contain a lot of information about your APIs and the order
in which they need to be executed for manual testing,
in a link:{pmtemplates}/pq/pq-sm.postman_collection.json[Structured Template].
Leveraging it can mitigate writing a lot of code as we translate those manual steps into automation.

____

* How _productive_ would it be, if you can plug your exported Postman collection,
that you anyway would have created for your manual testing, and execute them through your JVM tests?

* How about a Universal API automation tool promotes low code and low-cognitive-complexity and strikes a balance between flexibility and ease of use?

____

== API automation with _ReṼoman_

=== Template-Driven Testing

* The exported Postman collection JSON file is referred to as Postman templates, as it contains some placeholders/variables in the `{+{variable-key}+}` pattern. You can read more about it https://learning.postman.com/docs/sending-requests/variables/[here]
* ReṼoman understands these templates and replaces these variables at the runtime, similar to Postman. It supports
** Nested variables, e.g., `{{variable-key{+{nested-variable-key}+}}}`
** link:{sourcedir}/com/salesforce/revoman/internal/postman/DynamicVariableGenerator.kt[Dynamic variables], e.g., `{{$randomUUID}}`, `{{$randomEmail}}`
** Custom Dynamic variables—You can plug your own dynamic variable generator if the in-built ones don't fit your need.

You can _kick off_ this *Template-Driven Testing* by invoking `revUp`,
supplying your Postman templates and environments, and all your customizations through a configuration:

[source,java,indent=0,options="nowrap"]
----
final var rundown =
  ReVoman.revUp(
    Kick.configure()
     ...
    .off())
----

=== Simple Example

Let's start with a simple example.
Here] is an exported Postman collection to hit a free public https://restful-api.dev/[RESTFUL-API].
You can import and manually test this collection through the `Run collection` button like this:

image::resfulapi-dev-pm.png[]

You can automate the same
using ReṼoman in a link:{testdir}/com/salesforce/revoman/integration/restfulapidev/RestfulAPIDevTest.java[Junit test]
by supplying the template and environment path:

ifdef::env-github[]

[source,java,indent=0,options="nowrap"]
.link:{testdir}/com/salesforce/revoman/integration/restfulapidev/RestfulAPIDevTest.java[RestfulAPIDevTest.java, tag=revoman-simple-demo]
----
@Test
@DisplayName("restful-api.dev")
void restfulApiDev() {
  final var rundown =
    ReVoman.revUp( // <1>
      Kick.configure()
          .templatePath(PM_COLLECTION_PATH) // <2>
          .environmentPath(PM_ENVIRONMENT_PATH) // <3>
          .off());
  assertThat(rundown.stepReports).hasSize(3);
}
----
<1> `revUp` is the method to call passing a configuration, built as below
<2> Supply an exported Postman collection JSON file path
<3> Supply an exported Postman environment JSON file path

endif::[]
ifndef::env-github[]

[source,java,indent=0,options="nowrap"]
.link:{testdir}/com/salesforce/revoman/integration/restfulapidev/RestfulAPIDevTest.java[RestfulAPIDevTest.java, tag=revoman-simple-demo]
----
include::{testdir}/com/salesforce/revoman/integration/restfulapidev/RestfulAPIDevTest.java[tag=revoman-simple-demo]
----
<1> `revUp` is the method to call passing a configuration, built as below
<2> Supply an exported Postman collection JSON file path
<3> Supply an exported Postman environment JSON file path

endif::[]

=== Rundown

After all this, you receive back a detailed *Rundown* in return. It has all the Request-Response data for each step,
along with all Strong types that you configured, such that you can seamlessly run more assertions on top of the run.

[source,kotlin,indent=0,options="nowrap"]
----
Rundown(
  stepNameToReport: List<StepReport>,
  environment: PostmanEnvironment)

StepReport(
  step: Step,
  requestInfo: Either<RequestFailure, TxInfo<Request>>? = null, // <1>
  preHookFailure: PreHookFailure? = null,
  responseInfo: Either<ResponseFailure, TxInfo<Response>>? = null,
  postHookFailure: PostHookFailure? = null,
  envSnapshot: PostmanEnvironment<Any?> // <2>
)
----
<1> https://docs.vavr.io/#_either[`Either` type from the VAVR] library represents either of the two states, error or success
<2> Snapshot of Environment at the end of each step execution. It can be compared with previous or next step environment snapshots to see what changed in this step

[.lead]
`Rundown` has many convenience methods to ease applying further assertions on top of it.

TIP: Another simple example to see in Action: link:{testdir}/com/salesforce/revoman/integration/pokemon/PokemonTest.java[PokemonTest.java].

=== Advanced Example

[.lead]
ReṼoman isn't just limited to that;
you can add more _bells & whistles_ (Custom Dynamic variables, Request and Response Configs, Pre- and Post-Hooks) to it:

ifdef::env-github[]

[source,java,indent=0,options="nowrap"]
.link:{testdir}/com/salesforce/revoman/integration/core/pq/PQE2ETest.java[PQE2EWithSMTest.java, tag=pq-e2e-with-revoman-config-demo]
----
final var pqRundown =
  ReVoman.revUp( // <1>
    Kick.configure()
        .templatePaths(PQ_TEMPLATE_PATHS) // <2>
        .environmentPath(PQ_ENV_PATH) // <3>
        .dynamicEnvironment( // <4>
            Map.of(
                "$quoteFieldsToQuery", "LineItemCount, CalculationStatus",
                "$qliFieldsToQuery", "Id, Product2Id",
                "$qlrFieldsToQuery", "Id, QuoteId, MainQuoteLineId, AssociatedQuoteLineId"))
        .customDynamicVariable( // <5>
            "$quantity", ignore -> String.valueOf(Random.Default.nextInt(10) + 1))
        .haltOnAnyFailureExcept(afterAllStepsContainingHeader("ignoreForFailure")) // <6>
        .requestConfig( // <7>
            unmarshallRequest(
                beforeAllStepsWithURIPathEndingWith(PQ_URI_PATH),
                PlaceQuoteInputRepresentation.class,
                adapter(PlaceQuoteInputRepresentation.class)))
        .hooks( // <8>
            pre(
                beforeAllStepsWithURIPathEndingWith(PQ_URI_PATH),
                (step, requestInfo, rundown) -> {
                  final var pqInputRep =
                      requestInfo.<PlaceQuoteInputRepresentation>getTypedTxObj();
                  assertThat(pqInputRep).isNotNull();
                  if ("pq-create: qli+qlr (skip-pricing)"
                      .equals(pqInputRep.getGraph().getGraphId())) {
                    LOGGER.info("Skip pricing for step: {}", step);
                    rundown.mutableEnv.set("$pricingPref", PricingPref.Skip.toString());
                  } else {
                    rundown.mutableEnv.set("$pricingPref", PricingPref.System.toString());
                  }
                }),
            post(
                afterStepName("query-quote-and-related-records"),
                (ignore, rundown) -> assertAfterPQCreate(rundown.mutableEnv)),
            post(
                afterAllStepsWithURIPathEndingWith(PQ_URI_PATH),
                (stepReport, ignore) -> {
                  LOGGER.info(
                      "Waiting in PostHook for Step: {} for the Quote to get processed",
                      stepReport.step.displayName);
                  // ! CAUTION 10/09/23 gopala.akshintala: This can be flaky until
                  // polling is implemented
                  Thread.sleep(5000);
                }))
        .responseConfig( // <9>
            unmarshallSuccessResponse(
                afterStepName("quote-related-records"), CompositeResponse.class), // <10>
            validateIfSuccess( // <11>
                afterAllStepsWithURIPathEndingWith(PQ_URI_PATH),
                PlaceQuoteOutputRepresentation.class,
                VALIDATE_PQ_SUCCESS),
            validateIfFailed(
                afterAllStepsInFolder("errors|>sync"),
                PlaceQuoteOutputRepresentation.class,
                VALIDATE_PQ_SYNC_ERROR))
        .insecureHttp(true) // <12>
        .off()); // Kick-off
assertThat(pqRundown.firstUnIgnoredUnsuccessfulStepReport()).isNull();
assertThat(pqRundown.mutableEnv)
  .containsAllEntriesOf(
      Map.of(
          "quoteCalculationStatusForSkipPricing", PricingPref.Skip.completeStatus,
          "quoteCalculationStatus", PricingPref.System.completeStatus,
          "quoteCalculationStatusAfterAllUpdates", PricingPref.System.completeStatus));
----
<1> `revUp` is the method to call passing a configuration, built as below
<2> Supply the path (relative to resources) to the Template Collection JSON file
<3> Supply the path (relative to resources) to the Environment JSON file
<4> Supply any dynamic environment that is runtime-specific
<5> Plug Custom dynamic variables that are prepared at runtime
<6> It lets you be in charge of the Step Orchestration by letting you configure a pass-list of steps to ignore for failure
<7> You can provide a strong type for your request to be marshalled into. You can use this strong type while executing pre-hooks
<8> You can set up a pre- / post-hook around a Step via `hooks`, which can help as callbacks, especially for Async operations.
<9> Provide configuration to unmarshall/deserialize response JSON into strong types
<10> `unmarshallSuccessResponse` and `unmarshallErrorResponse` help you use strong types inside hooks.
<11> Supply your validations/assertions to be run on a step response through `validateIfSuccess` and `validateIfFailed`
** You can leverage the power of https://github.com/salesforce-misc/Vador[*Vador*] to write config-driven validations
<10> [Not for Prod] Ignore Java cert issues when firing HTTP calls

endif::[]
ifndef::env-github[]

[source,java,indent=0,options="nowrap"]
.link:{testdir}/com/salesforce/revoman/integration/core/pq/PQE2ETest.java[PQE2ETest.java, tag=pq-e2e-with-revoman-config-demo]
----
include::{testdir}/com/salesforce/revoman/integration/core/pq/PQE2EWithSMTest.java[tag=pq-e2e-with-revoman-config-demo]
----
<1> `revUp` is the method to call passing a configuration, built as below
<2> Supply the path (relative to resources) to the Template Collection JSON file
<3> Supply the path (relative to resources) to the Environment JSON file
<4> Supply any dynamic environment that is runtime-specific
<5> Plug Custom dynamic variables that are prepared at runtime
<6> It lets you be in charge of the Step Orchestration by letting you configure a pass-list of steps to ignore for failure
<7> You can provide a strong type for your request to be marshalled into. You can use this strong type while executing pre-hooks
<8> You can set up a pre- / post-hook around a Step via `hooks`, which can help as callbacks, especially for Async operations.
<9> Provide configuration to unmarshall/deserialize response JSON into strong types
<10> `unmarshallSuccessResponse` and `unmarshallErrorResponse` help you use strong types inside hooks.
<11> Supply your validations/assertions to be run on a step response through `validateIfSuccess` and `validateIfFailed`
** You can leverage the power of https://github.com/salesforce-misc/Vador[*Vador*] to write config-driven validations
<12> [Not for Prod] Ignore Java cert issues when firing HTTP calls

endif::[]

== Debugging

[.lead]
This tool has particular emphasis on Debugging experience.

The rundown you get as a return from `revUp` after the execution completes has everything you need to know about what happened during each step execution,
along with environment snapshot during that step execution. Here is what a debugger view of a Rundown looks like:

image:rundown.png[Rundown of all steps]

[.lead]
🔍 Let's zoom into a detailed view of one of those Step reports:

image:step-report.png[Step Report]

[.lead]
Here are the environment *key-value* pairs accumulated along the entire execution:

image:mutable-env.png[Mutable environment after the execution completion]

[.lead]
If something goes wrong at any stage during the Step execution, ReṼoman *fails-fast* and captures the `Failure` in StepReport:

[#_step_execution]
image:step-execution.png[Step Execution]

[.lead]
ReṼoman logs everything, so you can watch your console to check what's going on in the execution

[#_logging]
image:pq-exe-logging.gif[Monitor Execution]

== Features

=== Type Safety with flexible JSON <- -> POJO marshalling/serialization and unmarshalling/deserialization

* ReṼoman internally uses a modern JSON library called https://github.com/square/moshi[**Moshi**]
* There may be a POJO that inherits or contains legacy classes which are hard or impossible to serialize. ReṼoman lets you serialize such a legacy POJO by letting you pass `typesToIgnoreForMarshalling`, where you can filter-out these legacy classes.
* The payload may not map to POJO, and you may need a custom adapter for Conversion. Moshi has it covered for you with its advanced adapter mechanism and ReṼoman accepts Moshi adapters via `requestConfig`, `responseConfig` and `customAdapters`
* ReṼoman also comes bundled with link:{sourcedir}/com/salesforce/revoman/input/json/JsonReaderUtils.kt[JSON Reader utils] and link:{sourcedir}/com/salesforce/revoman/input/json/JsonWriterUtils.kt[JSON Writer utils] to help build Moshi adapters.

TIP: Refer link:{testdir}/com/salesforce/revoman/integration/core/pq/adapters/ConnectInputRepWithGraphAdapter.java[ConnectInputRepWithGraphAdapter]
for an advanced adapter use-case

* It also has link:{sourcedir}/com/salesforce/revoman/input/json/JsonPojoUtils.kt[JSON POJO Utils], which you can use to directly convert JSON to POJO and vice versa.

=== Pre- and Post-Hooks

* A hook lets you fiddle with the execution by plugging in your code before or after a Step execution.
* You can pass a `*StepPick` which is a `Predicate` used to qualify a step. ReṼoman comes with bundled under the namespace `PickUtils`. If those don't fit your need, you can write your own predicates.
* You get the stepName and the entire rundown of what happened prior to this step as parameters,
as demonstrated in link:{testdir}/com/salesforce/revoman/integration/core/pq/PQE2EWithSMTest.java[PQE2ETest.java, tag=pq-e2e-with-revoman-config-demo]

[source,java,indent=0,options="nowrap"]
----

.hooks(
  pre(
      PreTxnStepPick,
      (currentStepName, requestInfo, rundown) -> {
        //...callback-code...
      }),
  post(
      PostTxnStepPick,
      (currentStepName, rundown) -> {
        //...callback-code...
      })
)

----

* You can do things like assertion on the rundown or environment and even mutate the environment, such that the execution of subsequent steps picks up those changes.
* You can plug in your java code to create/generate values for environment variables which can be populated and picked-up by subsequent steps.For example, you may want to create some `xyzId` but you don't have a Postman collection, but instead a Java utility to generate/create it.You can invoke the utility in a pre-hook of a step (which uses the variable `{+{xyzId}+}` in its template) and set the value in `mutableEnv`, so the step can pick it from there.

=== Compose modular Executions

* You don't have to squash all your steps into one mega collection. Instead, you can break them into easy-to-manage modular collections. `revUp` accepts a list of collection paths through `templatePaths`
* But that doesn't mean you have to execute all these templates in one-go. You can make multiple `revUp` calls.

NOTE: Only `mutableEnv` is the mutable-shared state across step executions

* If you wish to compose these executions, you can do so by adding the previous execution's `mutableEnv` to current execution using `dynamicEnvironment` parameter. This also comes in handy when you wish to execute a common step (e.g. `UserSetup`) inside a test setup method and use that environment for all the tests.

=== Environment snapshot

* You can use `envSnapshot` to assert if a step has executed as expected.
* You can compare snapshots from different steps to monitor the execution progress.

== USP

=== Low-code

TIP: Here is an example of a low-code link:{testdir}/com/salesforce/revoman/integration/core/pq/PQE2EWithSMTest.java[**E2E test**] that automates *~70 steps*

[.lead]
Compared to a traditional Integration/Functional or E2E test, approximately, the amount of code needed is *89%* less using ReṼoman.
The above test doesn't just have low code, but also low in Cognitive Complexity and Transparent in what it does.

=== CI/CD integrability

* ReṼoman is like any JVM library that you can plug into any JVM program/test (e.g., JUnit tests or Integration tests).
* Apart from adding a dependency in the build tool, there is *no extra setup needed* to execute these tests with ReṼoman in CI/CD.

=== Up-to-date Postman collections that live along with Code in VCS

* A nice side effect is, this lets the Postman collections always stay up to date and the entire Postman collection guards each *check-in* in the form of a Test suite augmenting manual testing.
* Any day, you can find an up-to-date Postman collection for every feature you need to test, right in your VCS (Git) along with your code. Developers can import these templates directly from VCS into Postman for manual testing. This comes in very handy during a team blitz.

=== Unified framework for Automating __Persona-based__ Manual testing

* ReṼoman brings a *Unified &amp; Simplified Test strategy* across the mul-**T**-verse (Integration Tests, E2E Tests, and Manual testing with Postman) for any API.
* The automation stays as close as possible to Persona-based Manual testing, leading to Transparency and better Traceability of issues
* This forces engineers to think like *API-first customers* while writing tests.
* *Test Data setup:* You can use the ReṼoman for the Test data setup too. This eliminates the need for different teams to write their own internal utilities for data setup.
* *E2E Test* can even reside outside the Service repo, as long as it can hit the service API

== Perf

This entire execution of **~70 steps**, which includes **10 async steps**, took a mere *122 sec* on localhost.
This can be much better on auto-build environments.

image:pq-revoman-test-time.png[Localhost Test time on FTest console]

WARNING: ReṼoman internally is very light-weight, and the execution times are proportional
to how your server responds or your network speed.

== Internal Orchestration

image::orchestration.png[ReṼoman flow]

* It reads the environment JSON provided into in-memory.
* Then it reads and Inflates each static template in the collection, replacing variables at runtime from the in-memory environment
* It unmarshalls the request into Strong JVM types using `requestConfig` and executes the pre-hooks for the step
* It then does an HTTP request.
* It reads the response and executes Postscript JS on the response and updates the in-memory environment.
* It unmarshalls the response into Strong JVM types using the `responseConfig` supplied and lets you run *Type-safe* validations on the strong-type and fails-fast at first failure.
* Finally, all the post-hooks for the step get triggered
* The iteration continues for all the steps in the template collection

[.lead]
Here is the failure hierarchy of what can go wrong in this process

[#_failure_hierarchy]
image::failure-hierarchy.png[Failure Hierarchy]

== Future

[.lead]
The future looks bright with multiple impactful features in the pipeline:

* API metrics and Analytics
* *It's built with extensibility* in mind. It can easily be extended to support other template formats, e.g., Kaiju templates used for availability testing.
* In-built polling support for Async steps
* Payload generation
* Flow control through YAML config

== FAQs

=== Is Debugging challenging with ReṼoman?

* IDE debug points in the Prod code work as expected while running the test.
* Coming to FTest code, we debug when we don't understand what's going on in the code.
* Debugging necessarily doesn't have to be with a debug point in the IDE.
* To be able to debug, a developer needs to be informed about what went wrong and he/she should have ways to try and test an isolated portion of the run.
* In the case of ReṼoman, you have the whole Postman collection at your disposal along with the Rundown. The entire test is transparent.
* This experience is enhanced with <<_failure_hierarchy,Explicit Failures>> and <<_logging,Logging>>

=== Why not use https://learning.postman.com/docs/collections/using-newman-cli/command-line-integration-with-newman[Newman] or https://learning.postman.com/docs/postman-cli/postman-cli-overview/#comparing-the-postman-cli-and-newman[Postman CLI]?

* ReṼoman may be similar to Newman or Postman CLI when it comes to executing a Postman collection, but the _similarities end there_.
* Newman/Postman CLI are built for node cannot be executed within a JVM. Even if you are able to run with some hacky way, there is no easy way to assert results.
* ReṼoman is JVM first that lets you configure a lot more, and gives you back a detailed report to assert in a typesafe way
* Newman is limited and cannot be integrated into our automation model on JVM

== link:CONTRIBUTING.adoc[🙌🏼Wanna Collab & Contribute?]
